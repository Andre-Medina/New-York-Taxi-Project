{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3313be",
   "metadata": {},
   "source": [
    "This file downloads all the data, will take a very only time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be252073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ██████╗  ██████╗  ███╗   ██╗ ███████╗ ██╗  ██████╗\n",
    "# ██╔════╝ ██╔═══██╗ ████╗  ██║ ██╔════╝ ██║ ██╔════╝\n",
    "# ██║      ██║   ██║ ██╔██╗ ██║ █████╗   ██║ ██║  ███╗\n",
    "# ██║      ██║   ██║ ██║╚██╗██║ ██╔══╝   ██║ ██║   ██║\n",
    "# ╚██████╗ ╚██████╔╝ ██║ ╚████║ ██║      ██║ ╚██████╔╝\n",
    "#  ╚═════╝  ╚═════╝  ╚═╝  ╚═══╝ ╚═╝      ╚═╝  ╚═════╝\n",
    "# global variables that are chagned often\n",
    "\n",
    "# █▀▀ █▀▀ █▄ █ █▀▀ █▀█ ▄▀█ █\n",
    "# █▄█ ██▄ █ ▀█ ██▄ █▀▄ █▀█ █▄▄\n",
    "#\n",
    "# variable for skipping all the plotting code for debugging processing\n",
    "plotting = True\n",
    "\n",
    "# chose while taxi types to be processed\n",
    "process_ywl = True\n",
    "process_grn = True\n",
    "process_fhv = True\n",
    "process_hvf = True\n",
    "\n",
    "# limits data size and processes to be quicker (for testing only)\n",
    "testing = False\n",
    "start_month = 2        # testing var default 2\n",
    "number_of_months = 1   # testing var default 11\n",
    "start_day = 32         # testing var default 32ish\n",
    "number_of_days = 5     # testing var default 366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0503c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ██████╗  ██╗       ██████╗  ██████╗   █████╗  ██╗\n",
    "# ██╔════╝  ██║      ██╔═══██╗ ██╔══██╗ ██╔══██╗ ██║\n",
    "# ██║  ███╗ ██║      ██║   ██║ ██████╔╝ ███████║ ██║\n",
    "# ██║   ██║ ██║      ██║   ██║ ██╔══██╗ ██╔══██║ ██║\n",
    "# ╚██████╔╝ ███████╗ ╚██████╔╝ ██████╔╝ ██║  ██║ ███████╗\n",
    "#  ╚═════╝  ╚══════╝  ╚═════╝  ╚═════╝  ╚═╝  ╚═╝ ╚══════╝\n",
    "# ██╗   ██╗  █████╗  ██████╗  ███████╗\n",
    "# ██║   ██║ ██╔══██╗ ██╔══██╗ ██╔════╝\n",
    "# ██║   ██║ ███████║ ██████╔╝ ███████╗\n",
    "# ╚██╗ ██╔╝ ██╔══██║ ██╔══██╗ ╚════██║\n",
    "#  ╚████╔╝  ██║  ██║ ██║  ██║ ███████║\n",
    "#   ╚═══╝   ╚═╝  ╚═╝ ╚═╝  ╚═╝ ╚══════╝\n",
    "# v3.2.0\n",
    "# global variabels which can be tweeked\n",
    "\n",
    "# █▀▄ ▄▀█ ▀█▀ ▄▀█    █▀▄ █ █▀█\n",
    "# █▄▀ █▀█  █  █▀█    █▄▀ █ █▀▄\n",
    "#\n",
    "\n",
    "# main data directory\n",
    "download_dir = \"../../raw_data/\"\n",
    "\n",
    "#where the pre processed data goes\n",
    "processed_dir = \"../../processed_data/\" \n",
    "\n",
    "#where the tallying data goes\n",
    "tallied_dir = \"../../tallied_data/\" \n",
    "\n",
    "# intermediate file names\n",
    "processed_data_file = \"_processed_data_\"\n",
    "tally_s1_file = \"taxi_data_tallyed_s1.csv\"\n",
    "tally_s2_file = \"taxi_data_tallyed_s2.csv\"\n",
    "tally_s3_file = \"taxi_data_tallyed_s3.csv\"\n",
    "\n",
    "\n",
    "# █    ▀  █▀▀▄ █▀▀█ █▀▀█ █▀▀█ █  █ █▀▀\n",
    "# █   ▀█▀ █▀▀▄ █▄▄▀ █▄▄█ █▄▄▀ █▄▄█ ▀▀█\n",
    "# ▀▀▀ ▀▀▀ ▀▀▀  ▀ ▀▀ ▀  ▀ ▀ ▀▀ ▄▄▄█ ▀▀▀\n",
    "# imporint libarys used throughout\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import log, sqrt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import e\n",
    "\n",
    "import os.path\n",
    "import os\n",
    "from os.path import getsize\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from pyspark.sql.functions import rand\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import warnings\n",
    "\n",
    "# variable for skipping all the plotting code for debugging processing\n",
    "start_time = time.perf_counter()\n",
    "start_time_og = time.perf_counter()\n",
    "\n",
    "\n",
    "# ▀█▀ ▄▀█ ▀▄▀ █    █▀▄ ▄▀█ ▀█▀ ▄▀█\n",
    "#  █  █▀█ █ █ █    █▄▀ █▀█  █  █▀█\n",
    "#\n",
    "\n",
    "# file location\n",
    "file_base = \"_tripdata_\"\n",
    "\n",
    "# indexs for each of the main data set types\n",
    "ywl_i = 0\n",
    "grn_i = 1\n",
    "fhv_i = 2\n",
    "hvf_i = 3\n",
    "\n",
    "# used to identify which taxis to process\n",
    "process_taxi = [process_ywl, process_grn, process_fhv, process_hvf]\n",
    "\n",
    "# names related to each cab type in order\n",
    "taxi_file_names = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
    "full_names = [\"yellow cabs\", \"green cabs\",\n",
    "              \"for higher vheciles\", \"for higher high volume\"]\n",
    "\n",
    "#months in a year\n",
    "months_of_year = ['January', 'February', 'March', 'April', 'May',\n",
    "                  'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# column names for each cab type in order\n",
    "column_names = [\n",
    "    ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "     'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
    "     'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
    "     'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
    "     'total_amount', 'congestion_surcharge'],\n",
    "    ['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime',\n",
    "     'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID',\n",
    "     'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax',\n",
    "     'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge',\n",
    "     'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge'],\n",
    "    ['dispatching_base_num', 'pickup_datetime', 'dropoff_datetime',\n",
    "     'PULocationID', 'DOLocationID', 'SR_Flag'],\n",
    "    ['hvfhs_license_num', 'dispatching_base_num', 'pickup_datetime',\n",
    "     'dropoff_datetime', 'PULocationID', 'DOLocationID', 'SR_Flag']\n",
    "]\n",
    "\n",
    "# 2018 fhv files which was giving me trouble so added this schema for it\n",
    "bad_fhv_schema = [2, 2018, ['Pickup_DateTime', 'DropOff_datetime',\n",
    "                            'PULocationID', 'DOLocationID', 'SR_Flag',\n",
    "                            'dispatching_base_number']]\n",
    "\n",
    "\n",
    "# aliases for pickup time and dropoff time\n",
    "pickup_time = ['tpep_pickup_datetime', 'lpep_pickup_datetime',\n",
    "               'pickup_datetime', 'pickup_datetime', 'Pickup_DateTime']\n",
    "dropoff_time = ['tpep_dropoff_datetime', 'lpep_dropoff_datetime',\n",
    "                'dropoff_datetime', 'dropoff_datetime', 'DropOff_datetime']\n",
    "\n",
    "# irrelavent collumns that can be dropped\n",
    "irrelavent_columns = ['dispatching_base_number', 'DOtime', 'hvfhs_license_num',\n",
    "                      'dispatching_base_num', 'VendorID', 'store_and_fwd_flag',\n",
    "                      'extra', 'MTA_tax', 'improvement_surcharge',\n",
    "                      'tip_amount', 'tolls_amount', 'ehail_fee',\n",
    "                      'improvement_surcharge', 'congestion_surcharge']\n",
    "\n",
    "# array, for all the taxi count colls\n",
    "all_taxi_cols = [\n",
    "                \"2019_night\",\n",
    "                \"2019_morn\",\n",
    "                \"2019_arvo\",\n",
    "                \"2019_even\",\n",
    "                \"2020_night\",\n",
    "                \"2020_morn\",\n",
    "                \"2020_arvo\",\n",
    "                \"2020_even\"\n",
    "                ]\n",
    "\n",
    "# array for 2020 taxi count colls\n",
    "taxi_cols_2020 = [\n",
    "                 \"2020_night\",\n",
    "                 \"2020_morn\",\n",
    "                 \"2020_arvo\",\n",
    "                 \"2020_even\"]\n",
    "\n",
    "\n",
    "# ▀█▀ ▄▀█ ▀▄▀ █    █   █▀█ █▀▀ ▄▀█ ▀█▀ █ █▀█ █▄ █ █▀\n",
    "#  █  █▀█ █ █ █    █▄▄ █▄█ █▄▄ █▀█  █  █ █▄█ █ ▀█ ▄█\n",
    "#\n",
    "\n",
    "# location processing variables\n",
    "# locations that will be removed as considered invalid\n",
    "bad_locations = [1, 132, 138, 264, 265]\n",
    "\n",
    "# location of the location id file\n",
    "location_file = \"taxi+_zone_lookup.csv\"\n",
    "\n",
    "# list of boroughs names as in the location file\n",
    "boroughs_locations = [\"Bronx\", \"Brooklyn\", \"Manhattan\", \"Queens\",\n",
    "                      \"Staten Island\", \"EWR\", \"Unknown\"]\n",
    "\n",
    "\n",
    "# █▀▄ █▀█ █ █ █ █▄ █ █   █▀█ ▄▀█ █▀▄\n",
    "# █▄▀ █▄█ ▀▄▀▄▀ █ ▀█ █▄▄ █▄█ █▀█ █▄▀\n",
    "#\n",
    "\n",
    "# taxi data base url\n",
    "taxi_url = f\"https://s3.amazonaws.com/nyc-tlc/trip+data/\"\n",
    "\n",
    "# covid cases\n",
    "covid_url = \"https://data.cityofnewyork.us/api/views/rc75-m7u3/rows.csv?accessType=DOWNLOAD\"\n",
    "\n",
    "# location data\n",
    "location_url = \"https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\"\n",
    "\n",
    "# █▀▄ ▄▀█ ▀█▀ █▀▀    █▀▄ █▀▀ █▀▀ █▀\n",
    "# █▄▀ █▀█  █  ██▄    █▄▀ ██▄ █▀  ▄█\n",
    "#\n",
    "months_in_year = 12\n",
    "\n",
    "# years of data used\n",
    "years = [2019, 2020]\n",
    "\n",
    "# feb 2019 was when fhvhv file started\n",
    "fhvhv_started = [2, 2019]\n",
    "\n",
    "# late feb 2020 was when the first case of covid was observed in NYC\n",
    "covid_started = [2, 2020]\n",
    "\n",
    "# preprocessing arrays\n",
    "\n",
    "# hours each day to seperate each count\n",
    "day_time_breakdown = [0, 6, 12, 18]\n",
    "\n",
    "# day of the year covid started on\n",
    "covid_start_day = int(datetime.datetime.strptime(\n",
    "    \" \".join([str(int) for int in covid_started]),\n",
    "    \"%m %Y\").__format__(\"%j\"))\n",
    "\n",
    "# pretty self explanitory\n",
    "days_in_2020 = 366\n",
    "\n",
    "\n",
    "# █▀█ █ █ ▀█▀ █   █ █▀▀ █▀█ █▀\n",
    "# █▄█ █▄█  █  █▄▄ █ ██▄ █▀▄ ▄█\n",
    "# values for calculating outliers\n",
    "\n",
    "# all vals must be withing the .99 percent of data\n",
    "outlier_percent = (1 - .99) / 2\n",
    "\n",
    "# buffer for graphing and removing outliers from graphs\n",
    "fare_amount_graph_buffer = 15\n",
    "\n",
    "# accuracy when calculating the percentile\n",
    "percentile_accuracy = 0.00001\n",
    "\n",
    "\n",
    "# █▀▀ █▀█ █ █ █ █▀▄    █▀▄ █▀▀ █▀▀ █▀\n",
    "# █▄▄ █▄█ ▀▄▀ █ █▄▀    █▄▀ ██▄ █▄▄ ▄█\n",
    "#\n",
    "\n",
    "# files\n",
    "covid_restrictions_file = \"covid_restrictions.csv\"\n",
    "covid_cases_file = \"COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv\"\n",
    "\n",
    "# list of boroughs as named in the covid file (same order)\n",
    "covid_boroughs = [\"bx\", \"bk\", \"mn\", \"qn\", \"si\"]\n",
    "\n",
    "\n",
    "# █▀ █▀▀ ▀█▀ █ █ █▀█    █▀▀ █▀█ █▄ █ █▀▄ █ ▀█▀ █ █▀█ █▄ █ █▀\n",
    "# ▄█ ██▄  █  █▄█ █▀▀    █▄▄ █▄█ █ ▀█ █▄▀ █  █  █ █▄█ █ ▀█ ▄█\n",
    "#\n",
    "\n",
    "# plotting is using a yellow data set so must skip plotting if no yellow\n",
    "if plotting:\n",
    "    if not (process_taxi[ywl_i] and process_taxi[grn_i]):\n",
    "        plotting = False\n",
    "\n",
    "\n",
    "# if in a testing mode, sets up variables so file processes correctly\n",
    "if testing:\n",
    "\n",
    "    # changes the download dir to not overwrite data\n",
    "    download_dir += \"../test_download/\"\n",
    "\n",
    "    # changes some timing variabels to anaylise only what is needed for testing\n",
    "    covid_started[0] = start_month\n",
    "    months_in_year = start_month + number_of_months - 1\n",
    "    graph_month = start_month\n",
    "    days_in_2020 = start_day + number_of_days\n",
    "    days_in_common = days_in_2020\n",
    "else:\n",
    "\n",
    "    # i not testing graphing month is 5 (so may)\n",
    "    graph_month = 5\n",
    "\n",
    "\n",
    "# █▀▄▀█ █ █▀ █▀▀    █▀▀ █ █ █▄ █ █▀▀\n",
    "# █ ▀ █ █ ▄█ █▄▄    █▀  █▄█ █ ▀█ █▄▄\n",
    "# specialized functions\n",
    "\n",
    "# sets seed for when its used\n",
    "seed = 1\n",
    "\n",
    "\n",
    "# log function to deal with integer count data, added conditions to set\n",
    "# any negative or 0 values to be 0\n",
    "def logf(x):\n",
    "    return (log(x) if x > 0 else 0)\n",
    "\n",
    "\n",
    "# applys a log log others 0\n",
    "def loglogf(x):\n",
    "    return (log(log(x)) if x > e else 0)\n",
    "\n",
    "\n",
    "# applys log log to an array\n",
    "def loglogfa(arr):\n",
    "    return [loglogf(x) for x in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b32511f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/andre/Documents/2021/Applied Data Science/project 1/mast30034_2021_s2_project_1-Andre-Medina/code/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f32ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# █▀▄ █▀█ █ █ █ █▄ █ █   █▀█ ▄▀█ █▀▄    █▀▀ █ █ █▄ █ █▀▀\n",
    "# █▄▀ █▄█ ▀▄▀▄▀ █ ▀█ █▄▄ █▄█ █▀█ █▄▀    █▀  █▄█ █ ▀█ █▄▄\n",
    "#\n",
    "\n",
    "# script to download a file\n",
    "def download_file(url, location, file_name):\n",
    "\n",
    "    # prints download is starting\n",
    "    print(\"starting to download\" + file_name)\n",
    "\n",
    "    # downloads the file\n",
    "    urlretrieve(url, location + file_name)\n",
    "\n",
    "    # prints it has done downloading\n",
    "    print(\"Done downloading \" + file_name + \" to \\n\"\n",
    "          + location\n",
    "          + f\"\\n with size with size \\\n",
    "          {getsize(f'{location}') / 1073741824:.2f}GB \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2f9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to downloadCOVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv\n",
      "Done downloading COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv to \n",
      "../../raw_data/../test_download/\n",
      " with size with size           0.00GB \n",
      "\n",
      "\n",
      "starting to downloadtaxi+_zone_lookup.csv\n",
      "Done downloading taxi+_zone_lookup.csv to \n",
      "../../raw_data/../test_download/\n",
      " with size with size           0.00GB \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# █▀▀▄ █▀▀█ █   █ █▀▀▄ █   █▀▀█ █▀▀█ █▀▀▄  ▀  █▀▀▄ █▀▀▀\n",
    "# █  █ █  █ █▄█▄█ █  █ █   █  █ █▄▄█ █  █ ▀█▀ █  █ █ ▀█\n",
    "# ▀▀▀  ▀▀▀▀  ▀ ▀  ▀  ▀ ▀▀▀ ▀▀▀▀ ▀  ▀ ▀▀▀  ▀▀▀ ▀  ▀ ▀▀▀▀\n",
    "#\n",
    "\n",
    "# █▀█ ▀█▀ █ █ █▀▀ █▀█    █▀▄ ▄▀█ ▀█▀ ▄▀█\n",
    "# █▄█  █  █▀█ ██▄ █▀▄    █▄▀ █▀█  █  █▀█\n",
    "#\n",
    "\n",
    "# downloads the data\n",
    "download_file(covid_url, download_dir, covid_cases_file)\n",
    "\n",
    "# downloads the data\n",
    "download_file(location_url, download_dir, location_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac4b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to downloadgreen_tripdata_2019-02.csv\n",
      "Done downloading green_tripdata_2019-02.csv to \n",
      "../../raw_data/../test_download/\n",
      " with size with size           0.00GB \n",
      "\n",
      "\n",
      "starting to downloadfhv_tripdata_2019-02.csv\n",
      "Done downloading fhv_tripdata_2019-02.csv to \n",
      "../../raw_data/../test_download/\n",
      " with size with size           0.00GB \n",
      "\n",
      "\n",
      "starting to downloadgreen_tripdata_2020-02.csv\n",
      "Done downloading green_tripdata_2020-02.csv to \n",
      "../../raw_data/../test_download/\n",
      " with size with size           0.00GB \n",
      "\n",
      "\n",
      "starting to downloadfhv_tripdata_2020-02.csv\n",
      "Done downloading fhv_tripdata_2020-02.csv to \n",
      "../../raw_data/../test_download/\n",
      " with size with size           0.00GB \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#▀█▀ ▄▀█ ▀▄▀ █    █▀▄ ▄▀█ ▀█▀ ▄▀█\n",
    "# █  █▀█ █ █ █    █▄▀ █▀█  █  █▀█\n",
    "# downloads the relavent taxi data\n",
    "\n",
    "# loops over the years\n",
    "for year in years:\n",
    "\n",
    "    # for each taxi variant\n",
    "    for taxi_i in range(0, len(taxi_file_names)):\n",
    "\n",
    "        # tests if proccessing this taxi type:\n",
    "        if process_taxi[taxi_i]:\n",
    "\n",
    "            # loops over the months in years\n",
    "            for month in range(covid_started[0], months_in_year + 1):\n",
    "\n",
    "                # creates the relavent file name\n",
    "                file_name = taxi_file_names[taxi_i] + file_base \\\n",
    "                    + str(year) + '-' + str(month).zfill(2) + '.csv'\n",
    "\n",
    "                # gets the url to download from\n",
    "                url = taxi_url + file_name\n",
    "\n",
    "                # downloads the file\n",
    "                download_file(url, download_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b425d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
