{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/08 00:47:38 WARN Utils: Your hostname, DESKTOP-GN6J0KT resolves to a loopback address: 127.0.1.1; using 172.20.85.183 instead (on interface eth0)\n",
      "21/08/08 00:47:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/08/08 00:47:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "#█    ▀  █▀▀▄ █▀▀█ █▀▀█ █▀▀█ █  █ █▀▀ \n",
    "#█   ▀█▀ █▀▀▄ █▄▄▀ █▄▄█ █▄▄▀ █▄▄█ ▀▀█ \n",
    "#▀▀▀ ▀▀▀ ▀▀▀  ▀ ▀▀ ▀  ▀ ▀ ▀▀ ▄▄▄█ ▀▀▀ \n",
    "#\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from numpy import log, sqrt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import rand \n",
    "seed = 1\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "\n",
    "#variable for skipping all the plotting code for debugging processing\n",
    "plotting = False\n",
    "\n",
    "\n",
    "#█▀ █▀█ ▄▀█ █▀█ █▄▀ \n",
    "#▄█ █▀▀ █▀█ █▀▄ █ █ \n",
    "# spark set up\n",
    "\n",
    "#removes warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# create a spark session (which will run spark jobs)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# makes the outputted df nicely formatted\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "\n",
    "\n",
    "#█▀▄ ▄▀█ ▀█▀ ▄▀█    █▀▄ █ █▀█ \n",
    "#█▄▀ █▀█  █  █▀█    █▄▀ █ █▀▄ \n",
    "#\n",
    "\n",
    "#main data directory\n",
    "data_dir = \"/mnt/e/2021/Applied Data Science/Project 1/Data/\"\n",
    "\n",
    "#▀█▀ ▄▀█ ▀▄▀ █    █▀▄ ▄▀█ ▀█▀ ▄▀█ \n",
    "# █  █▀█ █ █ █    █▄▀ █▀█  █  █▀█ \n",
    "#\n",
    "\n",
    "#file location\n",
    "file_base = \"_tripdata_\"\n",
    "\n",
    "#indexs for each of the main data set types\n",
    "ywl_i = 0 \n",
    "grn_i = 1\n",
    "fhv_i = 2\n",
    "hvf_i = 3\n",
    "taxi_types_n = 4\n",
    "\n",
    "#names related to each cab type in order\n",
    "taxi_file_names = [\"yellow\",\"green\",\"fhv\",\"fhvhv\"]\n",
    "full_names = [\"yellow cabs\", \"green cabs\", \"for higher vheciles\", \"for higher high volume\"]\n",
    "\n",
    "#column names for each cab type in order\n",
    "column_names = [\n",
    "    ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge'],\n",
    "    ['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime', 'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge', 'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge'],\n",
    "    ['dispatching_base_num', 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID', 'SR_Flag'],\n",
    "    ['hvfhs_license_num', 'dispatching_base_num', 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID', 'SR_Flag']\n",
    "]\n",
    "\n",
    "#2018 fhv files which was giving me trouble so added this schema for it\n",
    "bad_fhv_schema = [2, 2018, ['Pickup_DateTime','DropOff_datetime', 'PULocationID', 'DOLocationID', 'SR_Flag','dispatching_base_number']]\n",
    "\n",
    "\n",
    "#aliases for pickup time and dropoff time\n",
    "pickup_time = ['tpep_pickup_datetime','lpep_pickup_datetime','pickup_datetime','pickup_datetime','Pickup_DateTime']\n",
    "dropoff_time = ['tpep_dropoff_datetime','lpep_dropoff_datetime','dropoff_datetime','dropoff_datetime','DropOff_datetime']\n",
    "\n",
    "#irrelavent collumns that can be dropped\n",
    "irrelavent_columns = ['dispatching_base_number','DOtime','hvfhs_license_num','dispatching_base_num','VendorID','store_and_fwd_flag','extra','MTA_tax','improvement_surcharge','tip_amount','tolls_amount', 'ehail_fee', 'improvement_surcharge', 'congestion_surcharge']\n",
    "\n",
    "\n",
    "#▀█▀ ▄▀█ ▀▄▀ █    █   █▀█ █▀▀ ▄▀█ ▀█▀ █ █▀█ █▄ █ █▀ \n",
    "# █  █▀█ █ █ █    █▄▄ █▄█ █▄▄ █▀█  █  █ █▄█ █ ▀█ ▄█ \n",
    "#\n",
    "\n",
    "#location processing variables\n",
    "#locations that will be removed as considered invalid\n",
    "bad_locations = [1,132,138,264,265]\n",
    "\n",
    "#location of the location id file\n",
    "location_file = \"taxi+_zone_lookup.csv\"\n",
    "\n",
    "#list of boroughs names as in the location file\n",
    "boroughs = [\"Bronx\",\"Brooklyn\",\"Manhattan\",\"Queens\",\"Staten Island\",\"EWR\",\"Unknown\"]\n",
    "\n",
    "\n",
    "#█▀▄ ▄▀█ ▀█▀ █▀▀    █▀▄ █▀▀ █▀▀ █▀ \n",
    "#█▄▀ █▀█  █  ██▄    █▄▀ ██▄ █▀  ▄█ \n",
    "#\n",
    "months_in_year = 12\n",
    "\n",
    "#years of data used\n",
    "years = [2018, 2019, 2020]\n",
    "\n",
    "#feb 2019 was when fhvhv file started\n",
    "fhvhv_started = [2,2019] \n",
    "\n",
    "#late feb 2020 was when the first case of covid was observed in NYC\n",
    "covid_started = [2,2020] \n",
    "\n",
    "#preprocessing arrays\n",
    "\n",
    "#hours each day to seperate each count\n",
    "day_time_breakdown = [0,6,12,18]\n",
    "\n",
    "#day of the year covid started on\n",
    "start_day = int(datetime.datetime.strptime(\n",
    "    \" \".join([str(int) for int in covid_started]), \n",
    "    \"%m %Y\").__format__(\"%j\"))\n",
    "\n",
    "#pretty self explanitory\n",
    "days_in_2020 = 366\n",
    "\n",
    "\n",
    "#█▀█ █ █ ▀█▀ █   █ █▀▀ █▀█ █▀ \n",
    "#█▄█ █▄█  █  █▄▄ █ ██▄ █▀▄ ▄█ \n",
    "#\n",
    "\n",
    "outlier_percent = 0.01\n",
    "fare_amount_graph_buffer = 15\n",
    "percentile_accuracy = 0.00001\n",
    "\n",
    "\n",
    "#█▀▀ █▀█ █ █ █ █▀▄    █▀▄ █▀▀ █▀▀ █▀ \n",
    "#█▄▄ █▄█ ▀▄▀ █ █▄▀    █▄▀ ██▄ █▄▄ ▄█ \n",
    "#\n",
    "\n",
    "#files\n",
    "covid_restrictions_file = \"covid_restrictions.csv\"\n",
    "covid_cases_file = \"COVID-19_Daily_Counts_of_Cases__Hospitalizations__and_Deaths.csv\"\n",
    "\n",
    "#list of boroughs as named in the covid file (same order)\n",
    "covid_boroughs =[\"bx\",\"bk\",\"mn\",\"qn\",\"si\"]\n",
    "\n",
    "#covid data of interest\n",
    "covid_of_interest = ['case_count', 'probable_case_count','hospitalized_count', 'death_count', 'probable_death_count',\n",
    "       'case_count_7day_avg', 'all_case_count_7day_avg', 'hospitalized_count_7day_avg',\n",
    "       'death_count_7day_avg', 'all_death_count_7day_avg']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_file = \"combined_taxi_data.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#█▀▀ █▀▀ █  █ █▀▀ █▀▄▀█ █▀▀█    █▀▀ █▀▀ ▀▀█▀▀ █  █ █▀▀█ \n",
    "#▀▀█ █   █▀▀█ █▀▀ █ ▀ █ █▄▄█    ▀▀█ █▀▀   █   █  █ █▄▄█ \n",
    "#▀▀▀ ▀▀▀ ▀  ▀ ▀▀▀ ▀   ▀ ▀  ▀    ▀▀▀ ▀▀▀   ▀    ▀▀▀ █    \n",
    "#\n",
    "\n",
    "ints = ('SR_Flag','VendorID', 'trip_type', 'passenger_count', 'RateCodeID', 'RatecodeID','payment_type','PULocationID','DOLocationID')\n",
    "doubles = ('trip_distance', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','ehail_fee',\n",
    "           'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount','congestion_surcharge')\n",
    "strings = ('dispatching_base_number','store_and_fwd_flag','dispatching_base_num','hvfhs_license_num')\n",
    "dtimes = ('DropOff_datetime','Pickup_DateTime','tpep_pickup_datetime', 'tpep_dropoff_datetime', 'lpep_pickup_datetime', 'lpep_dropoff_datetime', 'pickup_datetime', 'dropoff_datetime')\n",
    "\n",
    "dtypes = {column: IntegerType() for column in ints}\n",
    "dtypes.update({column: DoubleType() for column in doubles})\n",
    "dtypes.update({column: StringType() for column in strings})\n",
    "dtypes.update({column: TimestampType() for column in dtimes})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#schema generation used from the tutes\n",
    "schema = []\n",
    "for index in range(0,taxi_types_n):\n",
    "    schema.append(StructType())\n",
    "    for column in column_names[index]:\n",
    "        schema[index].add(column, # column name\n",
    "                   dtypes[column], # data type\n",
    "                   True # is nullable?\n",
    "                  )\n",
    "        \n",
    "        \n",
    "        \n",
    "#schema for the bad fhv file\n",
    "bad_fhv_schema.append(StructType())\n",
    "for column in bad_fhv_schema[2]:\n",
    "    bad_fhv_schema[3].add(column,\n",
    "                         dtypes[column],\n",
    "                         True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing yellow    \t2018-02\n",
      "making\n",
      "importing yellow    \t2018-03\n",
      "adding\n",
      "importing yellow    \t2018-04\n",
      "adding\n",
      "importing yellow    \t2018-05\n",
      "adding\n",
      "importing yellow    \t2018-06\n",
      "adding\n",
      "importing yellow    \t2018-07\n",
      "adding\n",
      "importing yellow    \t2018-08\n",
      "adding\n",
      "importing yellow    \t2018-09\n",
      "adding\n",
      "importing yellow    \t2018-10\n",
      "adding\n",
      "importing yellow    \t2018-11\n",
      "adding\n",
      "importing yellow    \t2018-12\n",
      "adding\n",
      "importing green    \t2018-02\n",
      "making\n",
      "importing green    \t2018-03\n",
      "adding\n",
      "importing green    \t2018-04\n",
      "adding\n",
      "importing green    \t2018-05\n",
      "adding\n",
      "importing green    \t2018-06\n",
      "adding\n",
      "importing green    \t2018-07\n",
      "adding\n",
      "importing green    \t2018-08\n",
      "adding\n",
      "importing green    \t2018-09\n",
      "adding\n",
      "importing green    \t2018-10\n",
      "adding\n",
      "importing green    \t2018-11\n",
      "adding\n",
      "importing green    \t2018-12\n",
      "adding\n",
      "importing fhv    \t2018-02\n",
      "making\n",
      "importing fhv    \t2018-03\n",
      "adding\n",
      "importing fhv    \t2018-04\n",
      "adding\n",
      "importing fhv    \t2018-05\n",
      "adding\n",
      "importing fhv    \t2018-06\n",
      "adding\n",
      "importing fhv    \t2018-07\n",
      "adding\n",
      "importing fhv    \t2018-08\n",
      "adding\n",
      "importing fhv    \t2018-09\n",
      "adding\n",
      "importing fhv    \t2018-10\n",
      "adding\n",
      "importing fhv    \t2018-11\n",
      "adding\n",
      "importing fhv    \t2018-12\n",
      "adding\n",
      "importing yellow    \t2019-02\n",
      "making\n",
      "importing yellow    \t2019-03\n",
      "adding\n",
      "importing yellow    \t2019-04\n",
      "adding\n",
      "importing yellow    \t2019-05\n",
      "adding\n",
      "importing yellow    \t2019-06\n",
      "adding\n",
      "importing yellow    \t2019-07\n",
      "adding\n",
      "importing yellow    \t2019-08\n",
      "adding\n",
      "importing yellow    \t2019-09\n",
      "adding\n",
      "importing yellow    \t2019-10\n",
      "adding\n",
      "importing yellow    \t2019-11\n",
      "adding\n",
      "importing yellow    \t2019-12\n",
      "adding\n",
      "importing green    \t2019-02\n",
      "making\n",
      "importing green    \t2019-03\n",
      "adding\n",
      "importing green    \t2019-04\n",
      "adding\n",
      "importing green    \t2019-05\n",
      "adding\n",
      "importing green    \t2019-06\n",
      "adding\n",
      "importing green    \t2019-07\n",
      "adding\n",
      "importing green    \t2019-08\n",
      "adding\n",
      "importing green    \t2019-09\n",
      "adding\n",
      "importing green    \t2019-10\n",
      "adding\n",
      "importing green    \t2019-11\n",
      "adding\n",
      "importing green    \t2019-12\n",
      "adding\n",
      "importing fhv    \t2019-02\n",
      "making\n",
      "importing fhv    \t2019-03\n",
      "adding\n",
      "importing fhv    \t2019-04\n",
      "adding\n",
      "importing fhv    \t2019-05\n",
      "adding\n",
      "importing fhv    \t2019-06\n",
      "adding\n",
      "importing fhv    \t2019-07\n",
      "adding\n",
      "importing fhv    \t2019-08\n",
      "adding\n",
      "importing fhv    \t2019-09\n",
      "adding\n",
      "importing fhv    \t2019-10\n",
      "adding\n",
      "importing fhv    \t2019-11\n",
      "adding\n",
      "importing fhv    \t2019-12\n",
      "adding\n",
      "importing fhvhv    \t2019-02\n",
      "making\n",
      "importing fhvhv    \t2019-03\n",
      "adding\n",
      "importing fhvhv    \t2019-04\n",
      "adding\n",
      "importing fhvhv    \t2019-05\n",
      "adding\n",
      "importing fhvhv    \t2019-06\n",
      "adding\n",
      "importing fhvhv    \t2019-07\n",
      "adding\n",
      "importing fhvhv    \t2019-08\n",
      "adding\n",
      "importing fhvhv    \t2019-09\n",
      "adding\n",
      "importing fhvhv    \t2019-10\n",
      "adding\n",
      "importing fhvhv    \t2019-11\n",
      "adding\n",
      "importing fhvhv    \t2019-12\n",
      "adding\n",
      "importing yellow    \t2020-02\n",
      "making\n",
      "importing yellow    \t2020-03\n",
      "adding\n",
      "importing yellow    \t2020-04\n",
      "adding\n",
      "importing yellow    \t2020-05\n",
      "adding\n",
      "importing yellow    \t2020-06\n",
      "adding\n",
      "importing yellow    \t2020-07\n",
      "adding\n",
      "importing yellow    \t2020-08\n",
      "adding\n",
      "importing yellow    \t2020-09\n",
      "adding\n",
      "importing yellow    \t2020-10\n",
      "adding\n",
      "importing yellow    \t2020-11\n",
      "adding\n",
      "importing yellow    \t2020-12\n",
      "adding\n",
      "importing green    \t2020-02\n",
      "making\n",
      "importing green    \t2020-03\n",
      "adding\n",
      "importing green    \t2020-04\n",
      "adding\n",
      "importing green    \t2020-05\n",
      "adding\n",
      "importing green    \t2020-06\n",
      "adding\n",
      "importing green    \t2020-07\n",
      "adding\n",
      "importing green    \t2020-08\n",
      "adding\n",
      "importing green    \t2020-09\n",
      "adding\n",
      "importing green    \t2020-10\n",
      "adding\n",
      "importing green    \t2020-11\n",
      "adding\n",
      "importing green    \t2020-12\n",
      "adding\n",
      "importing fhv    \t2020-02\n",
      "making\n",
      "importing fhv    \t2020-03\n",
      "adding\n",
      "importing fhv    \t2020-04\n",
      "adding\n",
      "importing fhv    \t2020-05\n",
      "adding\n",
      "importing fhv    \t2020-06\n",
      "adding\n",
      "importing fhv    \t2020-07\n",
      "adding\n",
      "importing fhv    \t2020-08\n",
      "adding\n",
      "importing fhv    \t2020-09\n",
      "adding\n",
      "importing fhv    \t2020-10\n",
      "adding\n",
      "importing fhv    \t2020-11\n",
      "adding\n",
      "importing fhv    \t2020-12\n",
      "adding\n",
      "importing fhvhv    \t2020-02\n",
      "making\n",
      "importing fhvhv    \t2020-03\n",
      "adding\n",
      "importing fhvhv    \t2020-04\n",
      "adding\n",
      "importing fhvhv    \t2020-05\n",
      "adding\n",
      "importing fhvhv    \t2020-06\n",
      "adding\n",
      "importing fhvhv    \t2020-07\n",
      "adding\n",
      "importing fhvhv    \t2020-08\n",
      "adding\n",
      "importing fhvhv    \t2020-09\n",
      "adding\n",
      "importing fhvhv    \t2020-10\n",
      "adding\n",
      "importing fhvhv    \t2020-11\n",
      "adding\n",
      "importing fhvhv    \t2020-12\n",
      "adding\n"
     ]
    }
   ],
   "source": [
    "#██╗ ███╗   ███╗ ██████╗   ██████╗  ██████╗  ████████╗ ██╗ ███╗   ██╗  ██████╗  \n",
    "#██║ ████╗ ████║ ██╔══██╗ ██╔═══██╗ ██╔══██╗ ╚══██╔══╝ ██║ ████╗  ██║ ██╔════╝  \n",
    "#██║ ██╔████╔██║ ██████╔╝ ██║   ██║ ██████╔╝    ██║    ██║ ██╔██╗ ██║ ██║  ███╗ \n",
    "#██║ ██║╚██╔╝██║ ██╔═══╝  ██║   ██║ ██╔══██╗    ██║    ██║ ██║╚██╗██║ ██║   ██║ \n",
    "#██║ ██║ ╚═╝ ██║ ██║      ╚██████╔╝ ██║  ██║    ██║    ██║ ██║ ╚████║ ╚██████╔╝ \n",
    "#╚═╝ ╚═╝     ╚═╝ ╚═╝       ╚═════╝  ╚═╝  ╚═╝    ╚═╝    ╚═╝ ╚═╝  ╚═══╝  ╚═════╝  \n",
    "# imports all the relavent csv files to \n",
    "\n",
    "\n",
    "#▀█▀ ▄▀█ ▀▄▀ █ \n",
    "# █  █▀█ █ █ █ \n",
    "#\n",
    "def read_csv(year, month, taxi_i, schema_used, drop_index):\n",
    "    return (\n",
    "        spark.read.csv(\n",
    "            data_dir + taxi_file_names[taxi_i] + file_base + str(year) + \"-\" + str(month).zfill(2) + \".csv\", \n",
    "            header=True, \n",
    "            schema=schema_used)\\\n",
    "        .withColumnRenamed(pickup_time[drop_index],\"PUtime\")# rename the time col\n",
    "        .withColumnRenamed(dropoff_time[drop_index],\"DOtime\")# rename other time col\n",
    "        .drop(*irrelavent_columns)\n",
    "        #.sample(False, 0.1, seed=seed).limit(10) #testing line        \n",
    "    )\n",
    "\n",
    "\n",
    "#spark data frame matrix\n",
    "dfm = {}\n",
    "\n",
    "for year in years:\n",
    "    dfm[year] = {}\n",
    "    \n",
    "    #for each taxi variant\n",
    "    for taxi_i in range(0,len(taxi_file_names)):\n",
    "        dfm[year][taxi_i] = 0\n",
    "           \n",
    "        #loops over the months in years\n",
    "        for month in range(covid_started[0], months_in_year + 1):\n",
    "            \n",
    "            if(bad_fhv_schema[1] == year and taxi_i == fhv_i):\n",
    "                \n",
    "                schema_used = bad_fhv_schema[3]\n",
    "                drop_index = 4\n",
    "            else:\n",
    "                schema_used = schema[taxi_i]\n",
    "                drop_index = taxi_i\n",
    "                \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            #small condition as fhvhv didnt always exist\n",
    "            if( (month >= fhvhv_started[0] and year >= fhvhv_started[1]) or taxi_i != hvf_i):\n",
    "                \n",
    "                #prints that the functions is processing\n",
    "                print(\"importing \" + taxi_file_names[taxi_i] + \"    \\t\" + str(year) + \"-\" + str(month).zfill(2))                \n",
    "                \n",
    "                \n",
    "                #checks if a df has been read to current taxi or not\n",
    "                if dfm[year][taxi_i]:\n",
    "                    \n",
    "                    print(\"adding\")\n",
    "                    #if its valid the df is added\n",
    "                    dfm[year][taxi_i] = dfm[year][taxi_i].union(read_csv(year, month, taxi_i, schema_used, drop_index))\n",
    "                else:\n",
    "                    \n",
    "                    print(\"making\")\n",
    "                    #reads the first dataframe\n",
    "                    dfm[year][taxi_i] = read_csv(year, month, taxi_i, schema_used, drop_index)\n",
    "            \n",
    "            else:\n",
    "                dfm[year][taxi_i] = None\n",
    "\n",
    "for year in years:\n",
    "    for taxi_i in range(0,len(taxi_file_names)):\n",
    "        if( dfm[year][taxi_i] ):\n",
    "            dfm[year][taxi_i] = dfm[year][taxi_i]#.orderBy(rand(seed=seed))).limit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#█▀▀ ▄▀█ █▀ █▀▀ █▀ \n",
    "#█▄▄ █▀█ ▄█ ██▄ ▄█ \n",
    "# #importing covid case data\n",
    "covid_cases = pd.read_csv(data_dir + covid_cases_file)\n",
    "\n",
    "#makes the names of columns lowercase\n",
    "covid_cases.columns = covid_cases.columns.str.lower()\n",
    "\n",
    "#makes the date column datetime object\n",
    "covid_cases['date_of_interest'] = covid_cases['date_of_interest']\\\n",
    "    .transform(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n",
    "\n",
    "#renaming some badly named columns\n",
    "covid_cases['probable_death_count'] = covid_cases['death_count_probable']\n",
    "covid_cases['hospitalized_count_7day_avg'] = covid_cases['hosp_count_7day_avg']\n",
    "covid_cases = covid_cases.drop(['death_count_probable','hosp_count_7day_avg'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#█▀█ █▀▀ █▀ ▀█▀ █▀█ █ █▀▀ ▀█▀ █ █▀█ █▄ █ █▀ \n",
    "#█▀▄ ██▄ ▄█  █  █▀▄ █ █▄▄  █  █ █▄█ █ ▀█ ▄█ \n",
    "#\n",
    "\n",
    "#importing covid restrictions data\n",
    "covid_restrictions = pd.read_csv(data_dir + covid_restrictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    \n",
    "    dft = dfm[2019][ywl_i].sample(False, 0.1, seed=0).limit(10000)\n",
    "    \n",
    "    #extracting all the \n",
    "    data = dft.select('fare_amount').toPandas()['fare_amount']\n",
    "    \n",
    "    # apply a log transformation for all x non-zero x points, else 0\n",
    "    dataL = data.apply(lambda x: log(x) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    sns.distplot(data, bins= round((data.max()-data.min())/(2)))\n",
    "    plt.xlim(data.quantile(outlier_percent)-fare_amount_graph_buffer, data.quantile(1-outlier_percent)+fare_amount_graph_buffer)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    plt.xlim(dataL.quantile(outlier_percent)-log(fare_amount_graph_buffer), dataL.quantile(1-outlier_percent)+log(fare_amount_graph_buffer))\n",
    "    sns.distplot(dataL, bins= round((dataL.max()-data.min()))*2)\n",
    "    plt.show()\n",
    "    \n",
    "    #tried other plots and they looked like shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    \n",
    "    #extracting all the \n",
    "    data = dft.select('trip_distance').toPandas()['trip_distance']\n",
    "    \n",
    "    # apply a log transformation for all x non-zero x points, else 0\n",
    "    dataL = data.apply(lambda x: log(x) if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    plt.xlim(data.quantile(outlier_percent)-fare_amount_graph_buffer, data.quantile(1-outlier_percent)+fare_amount_graph_buffer)\n",
    "    sns.distplot(data, bins= round((data.max()-data.min())*1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    plt.xlim(dataL.quantile(outlier_percent)-log(fare_amount_graph_buffer), dataL.quantile(1-outlier_percent)+log(fare_amount_graph_buffer))\n",
    "    sns.distplot(dataL, bins= round((dataL.max()-data.min()))*5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotting:\n",
    "    data = dft.select('fare_amount','trip_distance').toPandas()\n",
    "    data.plot.scatter(y='fare_amount',x='trip_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2018 yellow\n",
      "processing 2018 green\n",
      "processing 2018 fhv\n",
      "processing 2019 yellow\n",
      "processing 2019 green\n",
      "processing 2019 fhv\n",
      "processing 2019 fhvhv\n",
      "processing 2020 yellow\n",
      "processing 2020 green\n",
      "processing 2020 fhv\n",
      "processing 2020 fhvhv\n"
     ]
    }
   ],
   "source": [
    "#███████╗ ██╗ ██╗      ████████╗ ███████╗ ██████╗  ██╗ ███╗   ██╗  ██████╗  \n",
    "#██╔════╝ ██║ ██║      ╚══██╔══╝ ██╔════╝ ██╔══██╗ ██║ ████╗  ██║ ██╔════╝  \n",
    "#█████╗   ██║ ██║         ██║    █████╗   ██████╔╝ ██║ ██╔██╗ ██║ ██║  ███╗ \n",
    "#██╔══╝   ██║ ██║         ██║    ██╔══╝   ██╔══██╗ ██║ ██║╚██╗██║ ██║   ██║ \n",
    "#██║      ██║ ███████╗    ██║    ███████╗ ██║  ██║ ██║ ██║ ╚████║ ╚██████╔╝ \n",
    "#╚═╝      ╚═╝ ╚══════╝    ╚═╝    ╚══════╝ ╚═╝  ╚═╝ ╚═╝ ╚═╝  ╚═══╝  ╚═════╝  \n",
    "# removing values that dont make sense, etc\n",
    "\n",
    "\n",
    "#█   █▀█ █▀▀ ▄▀█ ▀█▀ █ █▀█ █▄ █ \n",
    "#█▄▄ █▄█ █▄▄ █▀█  █  █ █▄█ █ ▀█ \n",
    "# removing invalid locations\n",
    "\n",
    "#checks if location id is in the bad location list\n",
    "@F.udf(\"boolean\")\n",
    "def bad_location(LocationID):\n",
    "    if(LocationID):\n",
    "        return (int(LocationID) not in bad_locations)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#for each year and each taxi \n",
    "for year in years:\n",
    "    for taxi_i in range(0,len(taxi_file_names)):\n",
    "        if( dfm[year][taxi_i] ):\n",
    "            \n",
    "            print(\"processing \" + str(year) + \" \" + taxi_file_names[taxi_i])\n",
    "            dfm[year][taxi_i] = dfm[year][taxi_i]\\\n",
    "                .filter(\n",
    "                    (bad_location(col(\"PULocationID\"))) &\n",
    "                    (bad_location(col(\"DOLocationID\")))\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for taxi_i in [fhv_i, hvf_i]:\n",
    "        if( dfm[year][taxi_i] ):\n",
    "            dfm[year][taxi_i] = dfm[year][taxi_i]\\\n",
    "            .filter(\n",
    "                (col(\"SR_flag\").isNull())\n",
    "            ).drop(\"SR_flag\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following processing only makes sense for yellow and green taxis\n",
    "\n",
    "\n",
    "#█▀█ ▄▀█ █▀ █▀ █▀▀ █▄ █ █▀▀ █▀▀ █▀█ \n",
    "#█▀▀ █▀█ ▄█ ▄█ ██▄ █ ▀█ █▄█ ██▄ █▀▄ \n",
    "# removing invalid passenger counts\n",
    "\n",
    "#█▀█ ▄▀█ ▀█▀ █▀▀ █▀ \n",
    "#█▀▄ █▀█  █  ██▄ ▄█ \n",
    "# only keep standard rates\n",
    "\n",
    "#█▀█ ▄▀█ █▄█ █▀▄▀█ █▀▀ █▄ █ ▀█▀ \n",
    "#█▀▀ █▀█  █  █ ▀ █ ██▄ █ ▀█  █  \n",
    "# payment types which arent helpful\n",
    "for year in years:\n",
    "    for taxi_i in [ywl_i, grn_i]:\n",
    "        if( dfm[year][taxi_i] ):\n",
    "            dfm[year][taxi_i] = dfm[year][taxi_i]\\\n",
    "            .filter(\n",
    "                (\n",
    "                    (col(\"payment_type\") == 1) | \n",
    "                    (col(\"payment_type\") == 0)\n",
    "                ) &\n",
    "                (col(\"passenger_count\") > 0) &\n",
    "                (col(\"RateCodeID\") == 1)\n",
    "            )#.drop(\"RateCodeID\",\"passenger_count\",\"payment_type\")\n",
    "             \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#█▀▀ █▀█ █▀ ▀█▀    ▄▀█ █▀▄▀█ █▀█ █ █ █▄ █ ▀█▀ \n",
    "#█▄▄ █▄█ ▄█  █     █▀█ █ ▀ █ █▄█ █▄█ █ ▀█  █  \n",
    "# cost are sometimes bad, graphing what it looks like atm\n",
    "\n",
    "if plotting:\n",
    "    \n",
    "    dft = dfm[2019][ywl_i].sample(False, 0.1, seed=0).limit(10000)\n",
    "    \n",
    "    #extracting all the fare amounts\n",
    "    data = dft.select('fare_amount').select('fare_amount').toPandas()['fare_amount']\n",
    "    \n",
    "    #checking max and min\n",
    "    print([data.min(),data.max()])\n",
    "    \n",
    "    #taking the log transform \n",
    "    data = data.apply(lambda x: log(x) if x else 0)\n",
    "    \n",
    "    #plotting the log of fare amounts to view distribution\n",
    "    plt.xlim(data.quantile(outlier_percent)-log(fare_amount_graph_buffer), data.quantile(1-outlier_percent)+log(fare_amount_graph_buffer))\n",
    "    sns.distplot(data, bins= round((data.max()-data.min()))*4)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #dfm[2019][ywl_i].select(\"fare_amount\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#▀█▀ █▀█ █ █▀█    █▀▄ █ █▀ ▀█▀ ▄▀█ █▄ █ █▀▀ █▀▀ \n",
    "# █  █▀▄ █ █▀▀    █▄▀ █ ▄█  █  █▀█ █ ▀█ █▄▄ ██▄ \n",
    "#\n",
    "\n",
    "if plotting:\n",
    "        \n",
    "    #extracting all the fare amounts\n",
    "    data = dft.select('trip_distance').toPandas()['trip_distance']\n",
    "    \n",
    "    #checking max and min\n",
    "    print([data.min(),data.max()])\n",
    "    \n",
    "    #taking the log transform \n",
    "    data = data.apply(lambda x: log(x) if x else 0)\n",
    "    \n",
    "    #plotting the log of fare amounts to view distribution\n",
    "    plt.xlim(data.quantile(outlier_percent)-log(fare_amount_graph_buffer), data.quantile(1-outlier_percent)+log(fare_amount_graph_buffer))\n",
    "    sns.distplot(data, bins= round((data.max()-data.min()))*4)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #dfm[2019][ywl_i].select(\"fare_amount\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if plotting:\n",
    "        \n",
    "    data = dft.select('fare_amount','trip_distance').toPandas()\n",
    "    data.plot.scatter(y='fare_amount',x='trip_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2018 yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5, 36.5], [0.0, 11.12]]\n",
      "processing 2018 green\n",
      "[[4.5, 33.5], [0.64, 10.73]]\n",
      "processing 2019 yellow\n",
      "[[2.5, 33.0], [0.0, 12.0]]\n",
      "processing 2019 green\n",
      "[[4.0, 25.5], [0.49, 8.2]]\n",
      "processing 2020 yellow\n",
      "[[4.0, 37.0], [0.0, 13.44]]\n",
      "processing 2020 green\n",
      "[[4.0, 89.0], [0.0, 26.09]]\n"
     ]
    }
   ],
   "source": [
    "#ass fare amount is obviously dependent on trip distance, the one quantiles cant be calculated after processing the other set\n",
    "#so they must both be processed in the same filter\n",
    "\n",
    "for year in years:\n",
    "    for taxi_i in [ywl_i, grn_i]:\n",
    "        if( dfm[year][taxi_i] ):\n",
    "            \n",
    "            print(\"processing \" + str(year) + \" \" + taxi_file_names[taxi_i])\n",
    "            qt = dfm[year][taxi_i].approxQuantile(\n",
    "                [\"fare_amount\",'trip_distance'], \n",
    "                [outlier_percent,1-outlier_percent], \n",
    "                percentile_accuracy\n",
    "            )\n",
    "            print(qt)\n",
    "            \n",
    "            #2.5 is the miniumum fare_amount so if the fare quantile was lower than the minimum, it is raised\n",
    "            if qt[0][0] < 2.5 :\n",
    "                qt[0][0] = 2.5\n",
    "            \n",
    "            #less than a 0km trip shouldnt be counted so min of distance it set to 0 if it was lower.\n",
    "            if qt[1][0] < 0 :\n",
    "                qt[1][0] = 0\n",
    "                \n",
    "            #only keeps the middle percent% (depends on what percent was decided) to remove outliers \n",
    "            dfm[year][taxi_i] = dfm[year][taxi_i].filter(\n",
    "                (col(\"fare_amount\") > qt[0][0]) & \n",
    "                (col(\"fare_amount\") < qt[0][1]) &                \n",
    "                (col('trip_distance') > qt[1][0]) & \n",
    "                (col('trip_distance') < qt[1][1])\n",
    "            )#.drop(\"fare_amount\",\"total_amount\"'trip_distance')\n",
    "            \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if plotting:\n",
    "        \n",
    "    dft = dfm[2020][grn_i].sample(False, 0.1, seed=0).limit(10000)\n",
    "    data = dft.select('fare_amount','trip_distance').toPandas()\n",
    "    data.plot.scatter(y='fare_amount',x='trip_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#██████╗  ██████╗  ███████╗ ██████╗  ██████╗   ██████╗   ██████╗ ███████╗ ███████╗ ███████╗ ██╗ ███╗   ██╗  ██████╗  \n",
    "#██╔══██╗ ██╔══██╗ ██╔════╝ ██╔══██╗ ██╔══██╗ ██╔═══██╗ ██╔════╝ ██╔════╝ ██╔════╝ ██╔════╝ ██║ ████╗  ██║ ██╔════╝  \n",
    "#██████╔╝ ██████╔╝ █████╗   ██████╔╝ ██████╔╝ ██║   ██║ ██║      █████╗   ███████╗ ███████╗ ██║ ██╔██╗ ██║ ██║  ███╗ \n",
    "#██╔═══╝  ██╔══██╗ ██╔══╝   ██╔═══╝  ██╔══██╗ ██║   ██║ ██║      ██╔══╝   ╚════██║ ╚════██║ ██║ ██║╚██╗██║ ██║   ██║ \n",
    "#██║      ██║  ██║ ███████╗ ██║      ██║  ██║ ╚██████╔╝ ╚██████╗ ███████╗ ███████║ ███████║ ██║ ██║ ╚████║ ╚██████╔╝ \n",
    "#╚═╝      ╚═╝  ╚═╝ ╚══════╝ ╚═╝      ╚═╝  ╚═╝  ╚═════╝   ╚═════╝ ╚══════╝ ╚══════╝ ╚══════╝ ╚═╝ ╚═╝  ╚═══╝  ╚═════╝  \n",
    "# Adding generated features and changing forms of other features\n",
    "\n",
    "#█▀▄ ▄▀█ ▀█▀ █▀▀    ▄▀█ █▄ █ █▀▄    ▀█▀ █ █▀▄▀█ █▀▀ \n",
    "#█▄▀ █▀█  █  ██▄    █▀█ █ ▀█ █▄▀     █  █ █ ▀ █ ██▄ \n",
    "# adding in binned date and time\n",
    "\n",
    "#UDFs can only have one output\n",
    "#this UDF bins the time of the day into the specified groups with int output between 1 - n being the group number\n",
    "@F.udf(\"int\")\n",
    "def find_part_of_day(time):\n",
    "    \n",
    "    #finds hour of the day once to speed code a bit\n",
    "    hour = int(time.__format__(\"%H\"))\n",
    "    \n",
    "    #checks which part of the day that hour should be in\n",
    "    if hour < day_time_breakdown[1]:\n",
    "        return 0\n",
    "    elif hour < day_time_breakdown[2]:\n",
    "        return 1\n",
    "    elif hour < day_time_breakdown[3]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "#this UDF extracts the week of the year from the date time column\n",
    "#years are captured in the matrix level and months will become irrelavent shortly\n",
    "@F.udf(\"int\")\n",
    "def find_week_of_year(time):\n",
    "    return int(time.__format__(\"%U\"))\n",
    "\n",
    "#the individual days can then be subsorted by looking at the day of the week\n",
    "@F.udf(\"int\")\n",
    "def find_day_of_week(time):\n",
    "    return int(time.__format__(\"%w\"))\n",
    "\n",
    "#testdf = dfm[2020][ywl_i].withColumn(\"week_of_year\", find_week_of_year(col(\"PUtime\"))).withColumn(\"day_of_week\", find_day_of_week(col(\"PUtime\"))).withColumn(\"part_of_day\", find_part_of_day(col(\"PUtime\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#█   █▀█ █▀▀ ▄▀█ ▀█▀ █ █▀█ █▄ █ \n",
    "#█▄▄ █▄█ █▄▄ █▀█  █  █ █▄█ █ ▀█ \n",
    "# adding in borough number\n",
    "\n",
    "#first we need to get the location id to borough id matrix \n",
    "\n",
    "#reads the location id file\n",
    "borough_codes = pd.read_csv(data_dir + location_file)\n",
    "\n",
    "#finds the 'id' for each location interms of the 5 boroughs\n",
    "codes = []\n",
    "for index, row in borough_codes.iterrows():\n",
    "    codes.append(boroughs.index(row[\"Borough\"]))\n",
    "\n",
    "#adds said list to the dataframe    \n",
    "borough_codes['Borough_code'] = pd.Series(codes, index = borough_codes.index)\n",
    "\n",
    "#location \n",
    "@F.udf(\"int\")\n",
    "def find_borough_code(location):\n",
    "    return int(borough_codes.loc[borough_codes[\"LocationID\"] == int(location)][\"Borough_code\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2018 yellow\n",
      "processing 2018 green\n",
      "processing 2018 fhv\n",
      "processing 2019 yellow\n",
      "processing 2019 green\n",
      "processing 2019 fhv\n",
      "processing 2019 fhvhv\n",
      "processing 2020 yellow\n",
      "processing 2020 green\n",
      "processing 2020 fhv\n",
      "processing 2020 fhvhv\n"
     ]
    }
   ],
   "source": [
    "#applying location and date row transformations\n",
    "\n",
    "for year in years:\n",
    "    for taxi_i in range(0,len(taxi_file_names)):\n",
    "        if( dfm[year][taxi_i] ):\n",
    "            \n",
    "            print(\"processing \" + str(year) + \" \" + taxi_file_names[taxi_i])\n",
    "            dfm[year][taxi_i] = dfm[year][taxi_i]\\\n",
    "                .withColumn(\"PU_borough_code\", find_borough_code(col(\"PULocationID\")))\\\n",
    "                .withColumn(\"DO_borough_code\", find_borough_code(col(\"DOLocationID\")))\\\n",
    "                .withColumn(\"week_of_year\", find_week_of_year(col(\"PUtime\")))\\\n",
    "                .withColumn(\"day_of_week\", find_day_of_week(col(\"PUtime\")))\\\n",
    "                .withColumn(\"part_of_day\", find_part_of_day(col(\"PUtime\")))\\\n",
    "                #.drop(\"DOLocationID\",\"PULocationID\",\"PUtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting  2018 yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting  2018 green\n",
      "counting  2018 fhv\n",
      "counting  2018 fhvhv\n",
      "counting  2019 yellow\n",
      "counting  2019 green\n",
      "counting  2019 fhv\n",
      "counting  2019 fhvhv\n",
      "counting  2020 yellow\n",
      "counting  2020 green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 194:=======================================>            (153 + 13) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting  2020 fhv\n",
      "counting  2020 fhvhv\n"
     ]
    }
   ],
   "source": [
    "#█▀▀ █▀▀█ █  █ █▀▀▄ ▀▀█▀▀  ▀  █▀▀▄ █▀▀▀ \n",
    "#█   █  █ █  █ █  █   █   ▀█▀ █  █ █ ▀█ \n",
    "#▀▀▀ ▀▀▀▀  ▀▀▀ ▀  ▀   ▀   ▀▀▀ ▀  ▀ ▀▀▀▀ \n",
    "# As we have binned all the data into serveral differnt groups, we now need to count how many\n",
    "# are in each group\n",
    "\n",
    "dfc = {}\n",
    "for year in years:\n",
    "    dfc[year] = {}\n",
    "    \n",
    "    for taxi_i in range(0,len(taxi_file_names)):\n",
    "        dfc[year][taxi_i] = None\n",
    "        \n",
    "        print(\"counting \"+\" \"+str(year)+\" \"+taxi_file_names[taxi_i])\n",
    "        \n",
    "        if( dfm[year][taxi_i] ):\n",
    "        \n",
    "            dfc[year][taxi_i] = dfm[year][taxi_i]\\\n",
    "                .groupBy(\"week_of_year\",\"day_of_week\",\"PU_borough_code\",\"DO_borough_code\",\"part_of_day\")\\\n",
    "                .count()\\\n",
    "                .toPandas()\n",
    "        \n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n"
     ]
    }
   ],
   "source": [
    "#▀▀█▀▀ █▀▀█ █   █   █  █  ▀  █▀▀▄ █▀▀▀ \n",
    "#  █   █▄▄█ █   █   █▄▄█ ▀█▀ █  █ █ ▀█ \n",
    "#  ▀   ▀  ▀ ▀▀▀ ▀▀▀ ▄▄▄█ ▀▀▀ ▀  ▀ ▀▀▀▀ \n",
    "# Once all the bins are counted, we need to tally the corresponding bins into a useable dataframe\n",
    "\n",
    "#function for counting a specific combonation of binning\n",
    "def countthis_col(year, taxi_i, week, dayow, borough, part_of_day, borough_col):\n",
    "    #print(\"\\t subcount \"+\" \".join( [str(int) for int in [year, taxi_i]]))\n",
    "    \n",
    "    #returns the following sum from the counted dataframe\n",
    "    return dfc[year][taxi_i]\\\n",
    "        .loc[\n",
    "            (dfc[year][taxi_i][\"week_of_year\"] == week) &   #checks the week of the year matches\n",
    "            (dfc[year][taxi_i][\"day_of_week\"] == dayow) &   #checks the day of the week matches\n",
    "            (dfc[year][taxi_i][borough_col] == borough) &   #checks the borough matches\n",
    "            (dfc[year][taxi_i][\"part_of_day\"] == part_of_day)  #checks the part of the day matches\n",
    "        ]['count'].values.sum()   #calulates the sum of the counts\n",
    "\n",
    "#this function is used to call the above function for both Pick up and drop off locations\n",
    "def countthis(year, taxi_i, week, dayow, borough, part_of_day):\n",
    "    \n",
    "    #just returns the sum of the above function twice\n",
    "    return countthis_col(year, taxi_i, week, dayow, borough, part_of_day, \"PU_borough_code\")\\\n",
    "         + countthis_col(year, taxi_i, week, dayow, borough, part_of_day, \"DO_borough_code\")\n",
    "    \n",
    "    \n",
    "# returns an array of values or of 0s if it was empty  \n",
    "def add_this_covid_data(day, stdar, borough, fhv, vals, length):\n",
    "    if(vals.any()):\n",
    "        output[10*(day - stdar) + 2 * borough + fhv].extend(vals[0])\n",
    "    else:\n",
    "        output[10*(day - stdar) + 2 * borough + fhv].extend([0] * length)\n",
    "        \n",
    "#output is just an array for now\n",
    "output = [] \n",
    "\n",
    "#start day, moved here as is used for debugging periods\n",
    "stdar = start_day #7*4+4\n",
    "\n",
    "\n",
    "for day in range(stdar, days_in_2020):#100):#start_day+1):\n",
    "    print(day)#start_day)\n",
    "    #output.append([])\n",
    "    datetimeO = datetime.datetime.strptime( \" \".join( [str(int) for int in [day, covid_started[1]]]) ,\"%j %Y\" )\n",
    "    dayow = int(datetimeO.__format__(\"%w\"))\n",
    "    week = int(datetimeO.__format__(\"%U\"))\n",
    "    \n",
    "    for borough in range(0, len(covid_boroughs)):\n",
    "        \n",
    "        for fhv in range(0, 2):\n",
    "            #[10*(day - start_day) + 2 * borough + fhv]\n",
    "            output.append([\n",
    "                dayow,\n",
    "                week,\n",
    "                borough,\n",
    "                fhv\n",
    "            ])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for year in years:\n",
    "                \n",
    "                for part_of_day in range(0, len(day_time_breakdown)):\n",
    "                    #print(\"counting \"+\" \".join( [str(int) for int in [day, week, dayow, borough, fhv, year, part_of_day]]))\n",
    "                    \n",
    "                    count = 0\n",
    "                    #for fhv\n",
    "                    if( fhv == 1):\n",
    "                        for taxi_i in [fhv_i, hvf_i]:\n",
    "                            if( dfm[year][taxi_i] ):\n",
    "                                count += countthis(year, taxi_i, week, dayow, borough, part_of_day)\n",
    "                        \n",
    "                    #for non fhv\n",
    "                    else:\n",
    "                        for taxi_i in [ywl_i, grn_i]:\n",
    "                            if( dfm[year][taxi_i] ):\n",
    "                                count += countthis(year, taxi_i, week, dayow, borough, part_of_day)\n",
    "                                \n",
    "                    output[10*(day - stdar) + 2 * borough + fhv].append(count)#start_day) + 2 * borough + fhv].append(count)\n",
    "            \n",
    "            #adding relavent covid case numbers\n",
    "            \n",
    "            #adding general ones first\n",
    "            add_this_covid_data(day, stdar, borough, fhv, \n",
    "                covid_cases.loc[covid_cases['date_of_interest'] == datetimeO][covid_of_interest].values,\n",
    "                len(covid_of_interest)\n",
    "            )\n",
    "            \n",
    "            #adding borough specific ones second\n",
    "            add_this_covid_data(day, stdar, borough, fhv, \n",
    "                covid_cases.loc[covid_cases['date_of_interest'] == datetimeO][\n",
    "                [covid_boroughs[borough] + \"_\" + suffix \n",
    "                 for suffix in covid_of_interest]]\\\n",
    "                .values,\n",
    "                len(covid_of_interest)\n",
    "            )\n",
    "            \n",
    "            \n",
    "                    \n",
    "            #adding relavent covid restrictions\n",
    "            add_this_covid_data(day, stdar, borough, fhv, \n",
    "                covid_restrictions.loc[\n",
    "                    covid_restrictions[\"date\"] == int(datetime.datetime.timestamp(datetimeO)) #converts current rows date to unix and finds relavent restrictions\n",
    "                ].drop(\"date\", axis=1)\n",
    "                .values,\n",
    "                len(covid_restrictions.columns) - 1\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>borough</th>\n",
       "      <th>fhv</th>\n",
       "      <th>2018_night</th>\n",
       "      <th>2018_morn</th>\n",
       "      <th>2018_arvo</th>\n",
       "      <th>2018_even</th>\n",
       "      <th>2019_night</th>\n",
       "      <th>2019_morn</th>\n",
       "      <th>...</th>\n",
       "      <th>phase_2</th>\n",
       "      <th>phase_3</th>\n",
       "      <th>phase_4</th>\n",
       "      <th>large_capacity_public</th>\n",
       "      <th>gatherings</th>\n",
       "      <th>broadway</th>\n",
       "      <th>movies</th>\n",
       "      <th>stadium_capcity</th>\n",
       "      <th>indoor_religious</th>\n",
       "      <th>curfew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3340 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      day  week  borough  fhv  2018_night  2018_morn  2018_arvo  2018_even  \\\n",
       "0       6     4        0    0           0          0          0          0   \n",
       "1       6     4        0    1           0          0          0          0   \n",
       "2       6     4        1    0           0          0          0          0   \n",
       "3       6     4        1    1           0          0          0          0   \n",
       "4       6     4        2    0           0          0          0          0   \n",
       "...   ...   ...      ...  ...         ...        ...        ...        ...   \n",
       "3335    3    52        2    1           0          0          0          0   \n",
       "3336    3    52        3    0           0          0          0          0   \n",
       "3337    3    52        3    1           0          0          0          0   \n",
       "3338    3    52        4    0           0          0          0          0   \n",
       "3339    3    52        4    1           0          0          0          0   \n",
       "\n",
       "      2019_night  2019_morn  ...  phase_2  phase_3  phase_4  \\\n",
       "0              0          0  ...      1.0      1.0      1.0   \n",
       "1              0          0  ...      1.0      1.0      1.0   \n",
       "2              0          0  ...      1.0      1.0      1.0   \n",
       "3              0          0  ...      1.0      1.0      1.0   \n",
       "4              0          0  ...      1.0      1.0      1.0   \n",
       "...          ...        ...  ...      ...      ...      ...   \n",
       "3335           0          0  ...      1.0      1.0      1.0   \n",
       "3336           0          0  ...      1.0      1.0      1.0   \n",
       "3337           0          0  ...      1.0      1.0      1.0   \n",
       "3338           0          0  ...      1.0      1.0      1.0   \n",
       "3339           0          0  ...      1.0      1.0      1.0   \n",
       "\n",
       "      large_capacity_public  gatherings  broadway  movies  stadium_capcity  \\\n",
       "0                       1.0       500.0       1.0     1.0         100000.0   \n",
       "1                       1.0       500.0       1.0     1.0         100000.0   \n",
       "2                       1.0       500.0       1.0     1.0         100000.0   \n",
       "3                       1.0       500.0       1.0     1.0         100000.0   \n",
       "4                       1.0       500.0       1.0     1.0         100000.0   \n",
       "...                     ...         ...       ...     ...              ...   \n",
       "3335                    1.0        10.0       0.0     0.0              0.0   \n",
       "3336                    1.0        10.0       0.0     0.0              0.0   \n",
       "3337                    1.0        10.0       0.0     0.0              0.0   \n",
       "3338                    1.0        10.0       0.0     0.0              0.0   \n",
       "3339                    1.0        10.0       0.0     0.0              0.0   \n",
       "\n",
       "      indoor_religious  curfew  \n",
       "0                  1.0     0.0  \n",
       "1                  1.0     0.0  \n",
       "2                  1.0     0.0  \n",
       "3                  1.0     0.0  \n",
       "4                  1.0     0.0  \n",
       "...                ...     ...  \n",
       "3335               0.5     1.0  \n",
       "3336               0.5     1.0  \n",
       "3337               0.5     1.0  \n",
       "3338               0.5     1.0  \n",
       "3339               0.5     1.0  \n",
       "\n",
       "[3340 rows x 55 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ██████╗  ██╗   ██╗ ████████╗ ██████╗  ██╗   ██╗ ████████╗ \n",
    "#██╔═══██╗ ██║   ██║ ╚══██╔══╝ ██╔══██╗ ██║   ██║ ╚══██╔══╝ \n",
    "#██║   ██║ ██║   ██║    ██║    ██████╔╝ ██║   ██║    ██║    \n",
    "#██║   ██║ ██║   ██║    ██║    ██╔═══╝  ██║   ██║    ██║    \n",
    "#╚██████╔╝ ╚██████╔╝    ██║    ██║      ╚██████╔╝    ██║    \n",
    "# ╚═════╝   ╚═════╝     ╚═╝    ╚═╝       ╚═════╝     ╚═╝    \n",
    "#\n",
    "\n",
    "\n",
    "#the data has been outputted row by row in the following format\n",
    "#\n",
    "#data order, \n",
    "#date + general\n",
    "#      dayow, week, borough,\n",
    "#taxi \n",
    "#        fhv, for each years(\n",
    "#                     for each partofday( \n",
    "#                            count))\n",
    "#covid cases normal then borough\n",
    "#     'case_count', 'probable_case_count','hospitalized_count', 'death_count', 'probable_death_count',\n",
    "#       'case_count_7day_avg', 'all_case_count_7day_avg', 'hospitalized_count_7day_avg',\n",
    "#       'death_count_7day_avg', 'all_death_count_7day_avg'\n",
    "#restrictions\n",
    "#       'pre_k_schools', 'elementary_schools', 'middle_schools',\n",
    "#       'high_schools', 'construction', 'offices', 'phase_1', 'restaurants',\n",
    "#       'outdoor_dining', 'phase_2', 'phase_3', 'phase_4',\n",
    "#       'large_capacity_public', 'gatherings', 'broadway', 'movies',\n",
    "#       'stadium_capcity', 'indoor_religious', 'curfew'#\n",
    "\n",
    "\n",
    "\n",
    "#column names for final data frame\n",
    "columns =  [\"day\", \n",
    "            \"week\", \n",
    "            \"borough\", \n",
    "            \"fhv\", \n",
    "            \"2018_night\", \n",
    "            \"2018_morn\",\n",
    "            \"2018_arvo\",\n",
    "            \"2018_even\",\n",
    "            \"2019_night\", \n",
    "            \"2019_morn\",\n",
    "            \"2019_arvo\",\n",
    "            \"2019_even\",\n",
    "            \"2020_night\", \n",
    "            \"2020_morn\",\n",
    "            \"2020_arvo\",\n",
    "            \"2020_even\",\n",
    "            'total_case_count', \n",
    "            'total_probable_case_count',\n",
    "            'total_hospitalized_count', \n",
    "            'total_death_count', \n",
    "            'total_probable_death_count',\n",
    "            'total_case_count_7day_avg',\n",
    "            'total_all_case_count_7day_avg', \n",
    "            'total_hospitalized_count_7day_avg',\n",
    "            'total_death_count_7day_avg', \n",
    "            'total_all_death_count_7day_avg',\n",
    "            'borough_case_count', \n",
    "            'borough_probable_case_count',\n",
    "            'borough_hospitalized_count', \n",
    "            'borough_death_count', \n",
    "            'borough_probable_death_count',\n",
    "            'borough_case_count_7day_avg',\n",
    "            'borough_all_case_count_7day_avg', \n",
    "            'borough_hospitalized_count_7day_avg',\n",
    "            'borough_death_count_7day_avg', \n",
    "            'borough_all_death_count_7day_avg',\n",
    "            'pre_k_schools', \n",
    "            'elementary_schools', \n",
    "            'middle_schools',\n",
    "            'high_schools', \n",
    "            'construction', \n",
    "            'offices', \n",
    "            'phase_1', \n",
    "            'restaurants',\n",
    "            'outdoor_dining', \n",
    "            'phase_2', \n",
    "            'phase_3', \n",
    "            'phase_4',\n",
    "            'large_capacity_public', \n",
    "            'gatherings', \n",
    "            'broadway', \n",
    "            'movies',\n",
    "            'stadium_capcity', \n",
    "            'indoor_religious', \n",
    "            'curfew'\n",
    "    ]\n",
    "\n",
    "dfo = pd.DataFrame(output, columns = columns)\n",
    "dfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo.to_csv(data_dir + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>PU_borough_code</th>\n",
       "      <th>DO_borough_code</th>\n",
       "      <th>part_of_day</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week_of_year  day_of_week  PU_borough_code  DO_borough_code  part_of_day  \\\n",
       "0             22            1                0                3            1   \n",
       "1             26            3                2                2            0   \n",
       "2             13            3                2                2            0   \n",
       "5             44            0                1                2            0   \n",
       "6             30            6                2                2            0   \n",
       "7             39            4                1                3            1   \n",
       "8             26            3                2                2            1   \n",
       "9             44            0                3                3            0   \n",
       "10            30            6                3                3            0   \n",
       "11            48            2                0                3            1   \n",
       "12            35            2                2                2            0   \n",
       "13            39            4                3                3            1   \n",
       "14            17            5                2                2            1   \n",
       "16            35            2                1                3            1   \n",
       "18            22            1                0                2            1   \n",
       "19            44            0                2                2            0   \n",
       "20            35            2                2                2            1   \n",
       "21            48            2                2                2            1   \n",
       "22            35            2                0                3            1   \n",
       "24            13            3                3                2            1   \n",
       "25            39            4                2                2            1   \n",
       "27            30            6                2                2            1   \n",
       "28            22            1                1                3            1   \n",
       "29            17            5                3                3            0   \n",
       "30            17            5                2                3            1   \n",
       "31            26            3                0                3            1   \n",
       "32            48            1                2                2            3   \n",
       "\n",
       "    count  \n",
       "0       1  \n",
       "1       1  \n",
       "2       2  \n",
       "5       1  \n",
       "6       2  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  \n",
       "10      1  \n",
       "11      1  \n",
       "12      1  \n",
       "13      1  \n",
       "14      2  \n",
       "16      1  \n",
       "18      1  \n",
       "19      2  \n",
       "20      1  \n",
       "21      2  \n",
       "22      1  \n",
       "24      1  \n",
       "25      2  \n",
       "27      1  \n",
       "28      1  \n",
       "29      1  \n",
       "30      1  \n",
       "31      2  \n",
       "32      1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc[2020][1].loc[dfc[2020][1]['week_of_year']> 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>PUtime</th><th>RatecodeID</th><th>PULocationID</th><th>DOLocationID</th><th>passenger_count</th><th>trip_distance</th><th>fare_amount</th><th>total_amount</th><th>payment_type</th><th>trip_type</th><th>PU_borough_code</th><th>DO_borough_code</th><th>week_of_year</th><th>day_of_week</th><th>part_of_day</th></tr>\n",
       "<tr><td>2020-02-01 00:09:09</td><td>1</td><td>52</td><td>50</td><td>1</td><td>6.82</td><td>23.0</td><td>27.05</td><td>1</td><td>1</td><td>1</td><td>2</td><td>4</td><td>6</td><td>0</td></tr>\n",
       "<tr><td>2020-02-01 00:50:02</td><td>1</td><td>25</td><td>181</td><td>1</td><td>1.24</td><td>7.0</td><td>9.96</td><td>1</td><td>1</td><td>1</td><td>1</td><td>4</td><td>6</td><td>0</td></tr>\n",
       "<tr><td>2020-02-01 00:51:57</td><td>1</td><td>255</td><td>112</td><td>1</td><td>0.84</td><td>5.5</td><td>7.8</td><td>1</td><td>1</td><td>1</td><td>1</td><td>4</td><td>6</td><td>0</td></tr>\n",
       "<tr><td>2020-02-01 00:36:44</td><td>1</td><td>37</td><td>130</td><td>1</td><td>8.42</td><td>28.5</td><td>29.8</td><td>1</td><td>1</td><td>1</td><td>3</td><td>4</td><td>6</td><td>0</td></tr>\n",
       "<tr><td>2020-02-01 00:15:28</td><td>1</td><td>243</td><td>129</td><td>1</td><td>11.64</td><td>35.5</td><td>43.92</td><td>1</td><td>1</td><td>2</td><td>3</td><td>4</td><td>6</td><td>0</td></tr>\n",
       "<tr><td>2020-03-01 00:58:36</td><td>1</td><td>25</td><td>97</td><td>1</td><td>1.63</td><td>9.0</td><td>11.4</td><td>1</td><td>1</td><td>1</td><td>1</td><td>9</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>2020-03-01 00:40:29</td><td>1</td><td>41</td><td>249</td><td>3</td><td>8.47</td><td>27.0</td><td>38.81</td><td>1</td><td>1</td><td>2</td><td>2</td><td>9</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>2020-04-01 01:57:31</td><td>1</td><td>244</td><td>161</td><td>1</td><td>7.63</td><td>23.0</td><td>32.46</td><td>1</td><td>1</td><td>2</td><td>2</td><td>13</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>2020-04-01 01:05:59</td><td>1</td><td>41</td><td>244</td><td>1</td><td>2.78</td><td>12.0</td><td>15.3</td><td>1</td><td>1</td><td>2</td><td>2</td><td>13</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>2020-04-01 08:00:36</td><td>1</td><td>260</td><td>231</td><td>1</td><td>9.37</td><td>28.0</td><td>34.55</td><td>1</td><td>1</td><td>3</td><td>2</td><td>13</td><td>3</td><td>1</td></tr>\n",
       "<tr><td>2020-05-01 05:51:44</td><td>1</td><td>117</td><td>197</td><td>1</td><td>11.86</td><td>46.0</td><td>50.05</td><td>1</td><td>1</td><td>3</td><td>3</td><td>17</td><td>5</td><td>0</td></tr>\n",
       "<tr><td>2020-05-01 06:14:48</td><td>1</td><td>74</td><td>197</td><td>1</td><td>12.79</td><td>38.0</td><td>47.67</td><td>1</td><td>1</td><td>2</td><td>3</td><td>17</td><td>5</td><td>1</td></tr>\n",
       "<tr><td>2020-05-01 07:30:22</td><td>1</td><td>74</td><td>238</td><td>1</td><td>3.17</td><td>11.5</td><td>18.06</td><td>1</td><td>1</td><td>2</td><td>2</td><td>17</td><td>5</td><td>1</td></tr>\n",
       "<tr><td>2020-05-01 07:49:54</td><td>1</td><td>75</td><td>262</td><td>1</td><td>1.12</td><td>6.0</td><td>10.55</td><td>1</td><td>1</td><td>2</td><td>2</td><td>17</td><td>5</td><td>1</td></tr>\n",
       "<tr><td>2020-06-01 06:16:37</td><td>1</td><td>22</td><td>197</td><td>1</td><td>20.6</td><td>59.5</td><td>63.05</td><td>1</td><td>1</td><td>1</td><td>3</td><td>22</td><td>1</td><td>1</td></tr>\n",
       "<tr><td>2020-06-01 06:19:40</td><td>1</td><td>69</td><td>197</td><td>1</td><td>14.73</td><td>46.5</td><td>56.17</td><td>1</td><td>1</td><td>0</td><td>3</td><td>22</td><td>1</td><td>1</td></tr>\n",
       "<tr><td>2020-06-01 07:42:28</td><td>1</td><td>168</td><td>42</td><td>4</td><td>0.9</td><td>6.0</td><td>6.88</td><td>1</td><td>1</td><td>0</td><td>2</td><td>22</td><td>1</td><td>1</td></tr>\n",
       "<tr><td>2020-07-01 01:06:03</td><td>1</td><td>75</td><td>263</td><td>1</td><td>1.19</td><td>6.0</td><td>12.06</td><td>1</td><td>1</td><td>2</td><td>2</td><td>26</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>2020-07-01 06:03:08</td><td>1</td><td>78</td><td>197</td><td>1</td><td>16.72</td><td>48.5</td><td>58.67</td><td>1</td><td>1</td><td>0</td><td>3</td><td>26</td><td>3</td><td>1</td></tr>\n",
       "<tr><td>2020-07-01 06:16:22</td><td>1</td><td>69</td><td>134</td><td>1</td><td>13.69</td><td>49.5</td><td>59.17</td><td>1</td><td>1</td><td>0</td><td>3</td><td>26</td><td>3</td><td>1</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-------------------+----------+------------+------------+---------------+-------------+-----------+------------+------------+---------+---------------+---------------+------------+-----------+-----------+\n",
       "|             PUtime|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|total_amount|payment_type|trip_type|PU_borough_code|DO_borough_code|week_of_year|day_of_week|part_of_day|\n",
       "+-------------------+----------+------------+------------+---------------+-------------+-----------+------------+------------+---------+---------------+---------------+------------+-----------+-----------+\n",
       "|2020-02-01 00:09:09|         1|          52|          50|              1|         6.82|       23.0|       27.05|           1|        1|              1|              2|           4|          6|          0|\n",
       "|2020-02-01 00:50:02|         1|          25|         181|              1|         1.24|        7.0|        9.96|           1|        1|              1|              1|           4|          6|          0|\n",
       "|2020-02-01 00:51:57|         1|         255|         112|              1|         0.84|        5.5|         7.8|           1|        1|              1|              1|           4|          6|          0|\n",
       "|2020-02-01 00:36:44|         1|          37|         130|              1|         8.42|       28.5|        29.8|           1|        1|              1|              3|           4|          6|          0|\n",
       "|2020-02-01 00:15:28|         1|         243|         129|              1|        11.64|       35.5|       43.92|           1|        1|              2|              3|           4|          6|          0|\n",
       "|2020-03-01 00:58:36|         1|          25|          97|              1|         1.63|        9.0|        11.4|           1|        1|              1|              1|           9|          0|          0|\n",
       "|2020-03-01 00:40:29|         1|          41|         249|              3|         8.47|       27.0|       38.81|           1|        1|              2|              2|           9|          0|          0|\n",
       "|2020-04-01 01:57:31|         1|         244|         161|              1|         7.63|       23.0|       32.46|           1|        1|              2|              2|          13|          3|          0|\n",
       "|2020-04-01 01:05:59|         1|          41|         244|              1|         2.78|       12.0|        15.3|           1|        1|              2|              2|          13|          3|          0|\n",
       "|2020-04-01 08:00:36|         1|         260|         231|              1|         9.37|       28.0|       34.55|           1|        1|              3|              2|          13|          3|          1|\n",
       "|2020-05-01 05:51:44|         1|         117|         197|              1|        11.86|       46.0|       50.05|           1|        1|              3|              3|          17|          5|          0|\n",
       "|2020-05-01 06:14:48|         1|          74|         197|              1|        12.79|       38.0|       47.67|           1|        1|              2|              3|          17|          5|          1|\n",
       "|2020-05-01 07:30:22|         1|          74|         238|              1|         3.17|       11.5|       18.06|           1|        1|              2|              2|          17|          5|          1|\n",
       "|2020-05-01 07:49:54|         1|          75|         262|              1|         1.12|        6.0|       10.55|           1|        1|              2|              2|          17|          5|          1|\n",
       "|2020-06-01 06:16:37|         1|          22|         197|              1|         20.6|       59.5|       63.05|           1|        1|              1|              3|          22|          1|          1|\n",
       "|2020-06-01 06:19:40|         1|          69|         197|              1|        14.73|       46.5|       56.17|           1|        1|              0|              3|          22|          1|          1|\n",
       "|2020-06-01 07:42:28|         1|         168|          42|              4|          0.9|        6.0|        6.88|           1|        1|              0|              2|          22|          1|          1|\n",
       "|2020-07-01 01:06:03|         1|          75|         263|              1|         1.19|        6.0|       12.06|           1|        1|              2|              2|          26|          3|          0|\n",
       "|2020-07-01 06:03:08|         1|          78|         197|              1|        16.72|       48.5|       58.67|           1|        1|              0|              3|          26|          3|          1|\n",
       "|2020-07-01 06:16:22|         1|          69|         134|              1|        13.69|       49.5|       59.17|           1|        1|              0|              3|          26|          3|          1|\n",
       "+-------------------+----------+------------+------------+---------------+-------------+-----------+------------+------------+---------+---------------+---------------+------------+-----------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm[2020][1].sample(False, 1.0, seed=781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_of_year</th></tr>\n",
       "<tr><td>26</td></tr>\n",
       "<tr><td>44</td></tr>\n",
       "<tr><td>22</td></tr>\n",
       "<tr><td>13</td></tr>\n",
       "<tr><td>48</td></tr>\n",
       "<tr><td>9</td></tr>\n",
       "<tr><td>17</td></tr>\n",
       "<tr><td>35</td></tr>\n",
       "<tr><td>4</td></tr>\n",
       "<tr><td>39</td></tr>\n",
       "<tr><td>30</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+\n",
       "|week_of_year|\n",
       "+------------+\n",
       "|          26|\n",
       "|          44|\n",
       "|          22|\n",
       "|          13|\n",
       "|          48|\n",
       "|           9|\n",
       "|          17|\n",
       "|          35|\n",
       "|           4|\n",
       "|          39|\n",
       "|          30|\n",
       "+------------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm[2020][1].select(\"week_of_year\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>week_of_year</th></tr>\n",
       "<tr><td>34</td></tr>\n",
       "<tr><td>26</td></tr>\n",
       "<tr><td>47</td></tr>\n",
       "<tr><td>13</td></tr>\n",
       "<tr><td>43</td></tr>\n",
       "<tr><td>17</td></tr>\n",
       "<tr><td>4</td></tr>\n",
       "<tr><td>8</td></tr>\n",
       "<tr><td>39</td></tr>\n",
       "<tr><td>21</td></tr>\n",
       "<tr><td>30</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+\n",
       "|week_of_year|\n",
       "+------------+\n",
       "|          34|\n",
       "|          26|\n",
       "|          47|\n",
       "|          13|\n",
       "|          43|\n",
       "|          17|\n",
       "|           4|\n",
       "|           8|\n",
       "|          39|\n",
       "|          21|\n",
       "|          30|\n",
       "+------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm[2018][1].select(\"week_of_year\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>day_of_week</th></tr>\n",
       "<tr><td>1</td></tr>\n",
       "<tr><td>6</td></tr>\n",
       "<tr><td>3</td></tr>\n",
       "<tr><td>5</td></tr>\n",
       "<tr><td>4</td></tr>\n",
       "<tr><td>2</td></tr>\n",
       "<tr><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+\n",
       "|day_of_week|\n",
       "+-----------+\n",
       "|          1|\n",
       "|          6|\n",
       "|          3|\n",
       "|          5|\n",
       "|          4|\n",
       "|          2|\n",
       "|          0|\n",
       "+-----------+"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm[2020][1].select(\"day_of_week\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
